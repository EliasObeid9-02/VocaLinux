#import "../helpers.typ": ar, ar_std, en, en_std, en_clean

= #ar([الفصل الأول: مقدمة])


#ar_std([
  تعد واجهة الأوامر في لينكس (#en_std([CLI])) نموذجًا للقوة والكفاءة في عالم الحوسبة. بالنسبة للمطورين ومسؤولي الأنظمة والمستخدمين المتمرسين، فهي البيئة المثالية للتحكم الدقيق في النظام، حيث توفر سرعة لا مثيل لها في المهام المعقدة من خلال أوامر نصية موجزة. لكن هذه القوة تعتمد على افتراض مهم، وهو قدرة المستخدم على استخدام لوحة المفاتيح بسرعة ودقة. هذا الاعتماد الأساسي على الكتابة اليدوية يخلق حاجزًا كبيرًا، ويحول هذه الأداة الفعالة إلى مصدر استبعاد للعديد من الأفراد الماهرين.
])

== #ar([الحاجز الرقمي لسطر الأوامر])

#ar_std([
  يتمحور هذا المشروع حول المستخدمين الذين لا يعتبرون لوحة المفاتيح القياسية أداة للإنتاجية، بل عقبة. ويشمل ذلك الأفراد الذين يعانون من مجموعة من الإعاقات الحركية، مثل إصابات الإجهاد المتكرر (#en_std([RSI])) والتهاب المفاصل والشلل، والتي يمكن أن تجعل الكتابة المطولة أو المعقدة مؤلمة أو بطيئة أو حتى مستحيلة.

  في حين أن واجهات المستخدم الرسومية الحديثة (#en_std([GUIs])) قد حققت تقدمًا كبيرًا في مجال إمكانية الوصول، من خلال دمج ميزات مثل قارئات الشاشة، وأنماط العرض عالية التباين، والتحكم الصوتي القوي، إلا أن بيئة سطر الأوامر ظلت إلى حد كبير بيئة متقشفة. وقد ظهرت فجوة حرجة في إمكانية الوصول: فالأداة التي توفر أعمق مستوى من التحكم في النظام هي الأقل ملاءمة لأولئك الذين لا يستطيعون استخدام لوحة المفاتيح. ويواجه هذا المشروع هذه الفجوة بشكل مباشر، ساعياً إلى سد الفجوة بين نية الإنسان وتنفيذ الأوامر عبر الصوت.
])

== #ar([بوابة صوتية إلى لينكس])

#ar_std([
  لمعالجة الفجوة التي تم تحديدها في إمكانية الوصول، يقترح هذا المشروع نظامًا مزدوج المكونات مصممًا ليكون بمثابة بوابة صوتية إلى لينكس #en_std([shell]). تم تصميم الحل المقترح ليكون فعالاً وخفيف الوزن، مما يضمن قابليته للاستخدام عبر مجموعة واسعة من الأجهزة. وهذا لا يتطلب فقط مترجمًا متطورًا، بل أيضًا مكونًا متخصصًا للغاية في التعرف على الكلام، ومضبوطًا بدقة ليتناسب مع الصيغة الفريدة لسطر الأوامر.

  يتكون النظام من وحدتين أساسيتين تعملان معًا:

  #enum(
    [*نظام التعرف على الكلام المعدل (#en_std([ASR]))*: تتمثل مسؤولية هذه الوحدة في التقاط الكلمات المنطوقة من قبل المستخدم وتحويلها إلى نص خام. يجب أن تكون مصممة خصيصًا للتعرف على المفردات وأنماط الصوتيات الخاصة بأوامر #en_std([shell])، بما في ذلك القدرة على تمييز الأحرف الفردية لتهجئة #en_std([arguments]).],
    [*مترجم أوامر متخصص*: هذا هو جوهر المشروع من الناحية المنطقية. يتلقى النص الخام من نظام #en_std([ASR]) ويقوم بعدة مهام أساسية: يربط النص غير المنظم بأمر سليم، ويتحقق من الأخطاء النحوية، ويصحح الأخطاء الإملائية الشائعة، ويبني مسارات ملفات سليمة بذكاء من كلام المستخدم.]
  )
])

== #ar([الأهداف والغايات])

#ar_std([
  الهدف الأساسي من هذا المشروع هو تصميم وتطبيق وتقييم نظام نموذجي يوفر واجهة صوتية لا تحتاج إلى استخدام اليدين من أجل لينكس #en_std([shell])، مع التركيز على تحسين إمكانية الوصول للمستخدمين ذوي الإعاقات الجسدية.
  
  ولتحقيق هذا الهدف، تم تحديد المهام التالية:

  #enum(
    [لتحديد نموذج مناسب للتعرف التلقائي على الكلام (#en_std([ASR])) يكون خفيف الوزن وقويًا وقادرًا على التعرف على الأحرف بشكل مستقل.],
    [لتدريب وتعديل نموذج #en_std([ASR]) المحدد لتحسين أدائه ودقته خصيصًا لكتابة أوامر لينكس #en_std([shell]).],
    [تصميم بنية نظام تدمج بشكل فعال وحدة #en_std([ASR]) المعدلة مع محرك تفسير الأوامر المخصص.],
    [تطوير نموذج أولي عملي يمكنه التعرف على مجموعة أساسية من أوامر لينكس الشائعة وصياغتها بشكل صحيح.],
    [تقييم دقة النموذج الأولي وقابليته للاستخدام بناءً على مجموعة محددة مسبقًا من سيناريوهات الأوامر الصوتية.],
  )
])

== #ar([المجال والقيود])

#ar_std([
  لضمان إمكانية إنجاز المشروع في الإطار الزمني المحدد، تم تحديد نطاقه بعناية. سيركز المشروع حصريًا على #en_std([`bash` shell]) واللغة الإنجليزية ومجموعة مختارة من الأوامر من حزمة #en_std([GNU `coreutils`]).

  *الأوامر في المجال*:
  #align(center+top, grid(
      rows: (1.5em, 1.5em, 1.5em),
      columns: (1fr, 1fr, 1fr),
      `ls`,    `cd`,   `cp`,
      `mv`,    `rm`,   `mkdir`,
      `rmdir`, `echo`, `touch`,
    )
  )

  على الرغم من أن هذا المشروع لن ينشئ محركًا للتعرف على الكلام من الصفر، فإن جزءًا كبيرًا من العمل يتضمن اختيار وتعديل وضبط نموذج #en_std([ASR]) موجود بالفعل لتلبية المتطلبات المحددة لتدوين الأوامر. لن يدعم النظام، في نسخته الأولية، ميزات #en_std([shell]) المتقدمة مثل تسلسل الأوامر (#en_std([piping])) أو إعادة التوجيه أو تنفيذ برامج #en_std([shell]) النصية. تمت الإشارة إلى هذه الجوانب باعتبارها مجالات محتملة للعمل في المستقبل.
])

== #ar([الأبحاث المرجعية])

#ar_std([
  يعتمد هذا المشروع على الأسس التي وضعتها العديد من الأوراق البحثية الهامة في مجال التعرف على الكلام والتعلم العميق. توفر الأوراق التالية الأساس النظري والعملي للمكونات الأساسية لنظامنا.
])

=== #en_clean([Listen, Attend, and Spell])

#ar_std([
  تقدم هذه الورقة نموذج #en_std([Listen, Attend, and Spell (LAS)])، وهو شبكة عصبية شاملة للتعرف التلقائي على الكلام. وتقترح بنية جديدة تتكون من #en_std([\"Listener\"]) (مشفر) يعالج المدخلات الصوتية و#en_std([\"Speller\"]) (مفكك) يستخدم آلية الانتباه لتوليد النص المكتوب. يبسط نموذج #en_std([LAS]) عملية التعرف على الكلام التقليدية من خلال تعلم تدوين الكلام مباشرة من الصوت، وهو جوهر مكون تحويل الكلام إلى نص لدينا.
])

=== #en_clean([Attention is All You Need])

#ar_std([
  تقدم هذه الورقة البحثية الرائدة بنية #en_std([Transformer])، التي تستغني تمامًا عن التكرار والالتواءات، وتعتمد فقط على آليات الانتباه. على الرغم من عدم استخدام نموذج #en_std([Transformer]) الكامل في هذا المشروع، فإننا نستفيد من ابتكاره الرئيسي: #en_std([Multi-Head Attention]). تعزز هذه الآلية الانتباه القياسي من خلال تشغيله عدة مرات بالتوازي. يتعلم كل من ”رؤوس الانتباه“ هذه التركيز على أجزاء مختلفة من المدخلات، مما يسمح للنموذج بالاهتمام بشكل مشترك بالمعلومات من فضاءات تمثيلية فرعية مختلفة في وقت واحد. يتم الاستفادة من هذا المفهوم لتحسين قوة التمثيل لطبقة الانتباه في نموذجنا.
])

=== #en_clean([Attention-Based Models for Speech Recognition])

#ar_std([
  تستكشف هذه الورقة بشكل أعمق استخدام آليات الانتباه في التعرف على الكلام. وهي تقدم آلية انتباه مدركة للموقع تساعد النموذج على التعامل بشكل أفضل مع العبارات الطويلة والتكرارات. وهذا أمر مهم بشكل خاص لمشروعنا، لأنه يسمح للنموذج بالحفاظ على التركيز على الأجزاء ذات الصلة من الإشارة الصوتية عند نسخ أوامر أطول وأكثر تعقيدًا.
])

=== #en_clean([SpecAugment: A Simple Data Augmentation Method])

#ar_std([
  يقدم #en_std([SpecAugment]) تقنية بسيطة ولكنها فعالة للغاية لتعديل البيانات من أجل التعرف على الكلام. تعمل هذه التقنية مباشرة على مخطط الطيف الصوتي #en_std([log-mel]) للمدخلات الصوتية، وتطبق تقنية تشويه الزمن وإخفاء التردد وإخفاء الزمن لإنشاء نماذج أكثر قوة. من خلال دمج #en_std([SpecAugment]) في مسار التدريب لدينا، نهدف إلى تحسين مرونة النموذج في التعامل مع الاختلافات في الكلام وضوضاء الخلفية.
])

=== #en_clean([Scheduled Sampling for Sequence Prediction])

#ar_std([
  تتناول هذه الورقة مشكلة شائعة في تدريب نماذج تنبؤ السلاسل: التباين بين التدريب (باستخدام #en_std([\"teacher forcing\"])) والاستدلال (باستخدام تنبؤات النموذج نفسه). يوفر #en_std([Scheduled Sampling]) استراتيجية تعليمية منهجية تنتقل تدريجياً من #en_std([teacher forcing]) إلى استخدام تنبؤات النموذج نفسه أثناء التدريب. وهذا يساعد على سد الفجوة بين التدريب والاستدلال، مما يؤدي إلى أداء أفضل في سيناريوهات العالم الحقيقي.

])

== #ar([هيكل التوثيق])

#ar_std([
  تم تصميم التوثيق لتقديم نظرة عامة شاملة على المشروع. يتعمق الفصل الثاني في الأسس النظرية للتقنيات المستخدمة، بما في ذلك نموذج #en_std([LAS]). يقدم الفصل الثالث تفاصيل تصميم النظام وتنفيذه، بما في ذلك الهندسة المعمارية وتدريب النموذج وتكامل المكونات.
])

#pagebreak()
