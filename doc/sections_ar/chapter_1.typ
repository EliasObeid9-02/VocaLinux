#import "../helpers.typ": ar, ar_std, en, en_std

= #ar([الفصل الأول: مقدمة])

#ar_std([
  في عالم الحوسبة الحديثة، تظل واجهة الأوامر (#en_std([CLI])) أداة لا غنى عنها للمطورين ومسؤولي النظام والمستخدمين المحترفين. ومع أن كفاءتها وقوتها لا مثيل لها، إلا أنها تقدم منحنى تعليمي صعب للمبتدئين ويمكن أن تكون مرهقة لمن يعانون من إعاقات جسدية. يقدم هذا المشروع نظامًا مزدوجًا مصممًا لسد هذه الفجوة من خلال ترجمة الكلام البشري إلى أوامر لينكس قابلة للتنفيذ، مما يجعل واجهة برمجة تطبيقات واجهة الأوامر أكثر سهولة وسلاسة.
])

#linebreak()

== #ar([نظرة عامة على المشروع ودوافعه])

#ar_std([
  جوهر هذا المشروع هو نظام مزدوج يترجم اللغة المنطوقة بسلاسة إلى أوامر لينكس قابلة للتنفيذ. هذا النظام بدافع من الرغبة في تحسين التفاعل بين الإنسان والحاسوب، وجعله أكثر سهولة. التطبيقات المحتملة متنوعة، من مساعدة المستخدمين ذوي الإعاقات الجسدية التي تجعل الكتابة صعبة إلى تحسين سير عمل المطورين المتمرسين من خلال السماح لهم بتنفيذ الأوامر دون رفع أيديهم عن لوحة المفاتيح. من خلال تحويل الكلام إلى أوامر، نهدف إلى خلق بيئة حوسبة أكثر شمولية وكفاءة.
])


#linebreak()

== #ar([وصف المشكلة])

#ar_std([
  التحدي الرئيسي الذي يتناوله هذا المشروع هو النسخ الدقيق للغة التقنية - على وجه التحديد، أوامر لينكس - من الصوت المنطوق. غالبًا ما يتم تدريب أنظمة تحويل الكلام إلى نص على اللغة العامة، وتواجه صعوبة في التعامل مع الصيغة الفريدة والمصطلحات والبنية الخاصة بتعليمات سطر الأوامر. ويزيد غموض اللغة الطبيعية من تعقيد الأمر، حيث يمكن أن يكون لعبارة واحدة تفسيرات متعددة. لمواجهة ذلك، يطلب النظام من المستخدم التحدث بلغة طبيعية بتنسيق محدد. يضمن هذا التنسيق صحة الأمر طالما تم فهم الكلام بشكل صحيح.
])

#pagebreak()


== #ar([الأهداف والغايات])

#ar_std([
  الهدف الرئيسي من هذا المشروع هو تصميم وتطبيق وتقييم نظام مزدوج لترجمة الكلام إلى أوامر. ولتحقيق ذلك، حددنا الأهداف التالية:

  - تطبيق نموذج الاستماع والانتباه والتهجئة (#en_std([LAS])) لتحويل الأوامر المنطوقة إلى نص.
  - تصميم وبناء مترجم قائم على القواعد يربط النص المترجم بأوامر لينكس صالحة.
  - دمج نموذج الذكاء الاصطناعي والمترجم في نظام متماسك ووظيفي.
  - تقييم أداء النظام باستخدام مقاييس مثل معدل الخطأ في الكلمات (#en_std([WER])) لنموذج الذكاء الاصطناعي ودقة الأوامر للنظام ككل.
])

#linebreak()

== #ar([المجال والقيود])

#ar_std([
  يركز مجال المشروع على مجموعة فرعية محددة من أوامر لينكس، خاصة تلك المتعلقة بالتنقل في نظام الملفات ومعالجتها. تم تصميم النظام للتعرف على مجموعة محددة مسبقًا من الأوامر وخياراتها الشائعة.

  ومع ذلك، فإن المشروع له بعض القيود. قد يعتمد أداء النموذج على لهجة المتحدث ووضوح كلامه. كما أنه غير مصمم للتعامل مع الأوامر المعقدة والمتسلسلة أو البرامج النصية المخصصة. علاوة على ذلك، قد تقل فعاليته في البيئات الصاخبة، حيث قد يواجه نموذج التعرف على الكلام صعوبة في تمييز الأوامر عن ضوضاء الخلفية.
])

#linebreak()

== #ar([مجموعة التقنيات المستخدمة])

#ar_std([
  يعتمد تطبيق هذا المشروع على مجموعة من المكتبات مفتوحة المصدر القوية والواسعة الاستخدام. تم تطوير جوهر النظام بلغة #en_std([Python])، مستفيدًا من نظامها البيئي الواسع النطاق في مجال الحوسبة العلمية والتعلم العميق.

  - *هيكلية التعلم العميق*: يتم إنشاء نموذج التعرف على الكلام وتدريبه وتقييمه باستخدام #en_std([*\"TensorFlow\"*]) بوساطة واجهة برمجة التطبيقات #en_std([*\"Keras\"*]) عالية المستوى. وهذا يوفر الأدوات الأساسية لإنشاء طبقات مخصصة، بما في ذلك طبقات #en_std([`Bidirectional`]) و#en_std([`LSTM`]) و#en_std([`Dense`])، والتي تعتبر أساسية في بنية #en_std([LAS]).
  - *المعالجة الرقمية والصوتية*: تُستخدم #en_std([*\"NumPy\"*]) لإجراء عمليات رقمية فعالة ومعالجة مصفوفات البيانات. لمعالجة الملفات الصوتية، تُستخدم مكتبة #en_std([*\"SoundFile\"*]) لقراءة البيانات الصوتية بتنسيق مناسب للمعالجة بواسطة النموذج.
  - *التقييم*: لقياس أداء مكون التعرف على الكلام، يتم استخدام مكتبة #en_std([*\"Jiwer\"*]). وهي توفر طريقة تنفيذ موحدة لحساب معدل الخطأ في الكلمات (#en_std([WER]))، وهو مقياس رئيسي لهذا المشروع.
])

#linebreak()

== #ar([الأبحاث المرجعية])

#ar_std([
  يعتمد هذا المشروع على الأسس التي وضعتها العديد من الأوراق البحثية الهامة في مجال التعرف على الكلام والتعلم العميق. توفر الأوراق التالية الأساس النظري والعملي للمكونات الأساسية لنظامنا.
])

#linebreak()

=== #en([Listen, Attend, and Spell])

#ar([
  تقدم هذه الورقة نموذج #en_std([Listen, Attend, and Spell (LAS)])، وهو شبكة عصبية شاملة للتعرف التلقائي على الكلام. وتقترح بنية جديدة تتكون من #en_std([\"Listener\"]) (مشفر) يعالج المدخلات الصوتية و#en_std([\"Speller\"]) (مفكك) يستخدم آلية الانتباه لتوليد النص المكتوب. يبسط نموذج #en_std([LAS]) عملية التعرف على الكلام التقليدية من خلال تعلم نسخ الكلام مباشرة من الصوت، وهو جوهر مكون تحويل الكلام إلى نص لدينا.
])

=== #en([Attention is All You Need])

#ar([
  تقدم هذه الورقة البحثية الرائدة بنية #en_std([Transformer])، التي تستغني تمامًا عن التكرار والالتواءات، وتعتمد فقط على آليات الانتباه. على الرغم من عدم استخدام نموذج #en_std([Transformer]) الكامل في هذا المشروع، فإننا نستفيد من ابتكاره الرئيسي: #en_std([Multi-Head Attention]). تعزز هذه الآلية الانتباه القياسي من خلال تشغيله عدة مرات بالتوازي. يتعلم كل من ”رؤوس الانتباه“ هذه التركيز على أجزاء مختلفة من المدخلات، مما يسمح للنموذج بالاهتمام بشكل مشترك بالمعلومات من فضاءات تمثيلية فرعية مختلفة في وقت واحد. يتم الاستفادة من هذا المفهوم لتحسين قوة التمثيل لطبقة الانتباه في نموذجنا.
])

#pagebreak()

=== #en([Attention-Based Models for Speech Recognition])

#ar_std([
  تستكشف هذه الورقة بشكل أعمق استخدام آليات الانتباه في التعرف على الكلام. وهي تقدم آلية انتباه مدركة للموقع تساعد النموذج على التعامل بشكل أفضل مع العبارات الطويلة والتكرارات. وهذا أمر مهم بشكل خاص لمشروعنا، لأنه يسمح للنموذج بالحفاظ على التركيز على الأجزاء ذات الصلة من الإشارة الصوتية عند نسخ أوامر أطول وأكثر تعقيدًا.
])

=== #en([SpecAugment: A Simple Data Augmentation Method])

#ar_std([
  يقدم #en_std([SpecAugment]) تقنية بسيطة ولكنها فعالة للغاية لتعديل البيانات من أجل التعرف على الكلام. تعمل هذه التقنية مباشرة على مخطط الطيف الصوتي #en_std([log-mel]) للمدخلات الصوتية، وتطبق تقنية تشويه الزمن وإخفاء التردد وإخفاء الزمن لإنشاء نماذج أكثر قوة. من خلال دمج #en_std([SpecAugment]) في مسار التدريب لدينا، نهدف إلى تحسين مرونة النموذج في التعامل مع الاختلافات في الكلام وضوضاء الخلفية.
])

=== #en([Scheduled Sampling for Sequence Prediction])

#ar_std([
  تتناول هذه الورقة مشكلة شائعة في نماذج التنبؤ بتسلسل التدريب: التباين بين التدريب (باستخدام #en_std([\"teacher forcing\"])) والاستدلال (باستخدام تنبؤات النموذج نفسه). يوفر #en_std([Scheduled Sampling]) استراتيجية تعليمية مناهجية تنتقل تدريجياً من #en_std([teacher forcing]) إلى استخدام تنبؤات النموذج نفسه أثناء التدريب. وهذا يساعد على سد الفجوة بين التدريب والاستدلال، مما يؤدي إلى أداء أفضل في سيناريوهات العالم الحقيقي.
])

#linebreak()

== #ar([هيكل التوثيق])

#ar_std([
  تم تصميم التوثيق لتقديم نظرة عامة شاملة على المشروع. يتعمق الفصل الثاني في الأسس النظرية للتقنيات المستخدمة، بما في ذلك نموذج #en_std([LAS]). يقدم الفصل الثالث تفاصيل تصميم النظام وتنفيذه، بما في ذلك الهندسة المعمارية وتدريب النموذج وتكامل المكونات.
])

#pagebreak()
